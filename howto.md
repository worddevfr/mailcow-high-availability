<div align="center">
    <img src="logo.png" alt="Mailcow ISP" height="20%" width="20%" style="vertical-align: middle;">
</div>

<h1 align="center">Mailcow ISP</h1>

<p align="center">
    ‚≠ê If you like this project, <strong>consider giving it a star</strong> ‚Äî it really keeps us motivated! ‚≠ê<br>
    ‚≠ê Si ce projet vous pla√Æt, <strong>pensez √† lui mettre une √©toile</strong> ‚Äî √ßa nous motive √©norm√©ment ! ‚≠ê

<p>&nbsp;</p>

<p align="center">
  <a href="https://github.com/mailcow/mailcow-dockerized" target="_blank">
    <img src="https://img.shields.io/badge/MAILCOW-FFC107?style=for-the-badge&logoColor=white" alt="Mailcow"/>
  </a>
  <a href="https://www.docker.com/" target="_blank">
    <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker"/>
  </a>
  <a href="https://www.keepalived.org/" target="_blank">
    <img src="https://img.shields.io/badge/Keepalived-009688?style=for-the-badge" alt="Keepalived"/>
  </a>
  <a href="https://www.hetzner.com/cloud" target="_blank">
    <img src="https://img.shields.io/badge/Hetzner%20Cloud-D50C2D?style=for-the-badge&logo=hetzner&logoColor=white" alt="Hetzner"/>
  </a>
  <a href="https://www.gnu.org/software/bash/" target="_blank">
    <img src="https://img.shields.io/badge/GNU%20Bash-4EAA25?style=for-the-badge&logo=gnubash&logoColor=white" alt="GNU Bash"/>
  </a>
<br><br>
</p>

<details>
<summary><strong>üá¨üáß English Version (click to expand)</strong></summary>

### üìÑ Detailed Technical Architecture

### 1. Philosophy and Objectives

A standard Mailcow instance, while powerful, is a **Single Point of Failure (SPOF)**. A hardware failure, a faulty update, or a critical container crash is enough to bring down the entire mail service.

The goal of **Mailcow-HA** is to transform this single instance into a **resilient Active/Passive cluster**, capable of surviving most failures by automatically failing over the service to a standby node, with zero human intervention and minimal service interruption.

This solution is designed as an **orchestration layer** that integrates with a standard Mailcow installation without modifying its core, ensuring full compatibility with future Mailcow updates.

---

### 2. The Four Pillars of the Infrastructure

The cluster's robustness is built on four fundamental components working in concert.

##### üèõÔ∏è **Pillar 1: The Application Nodes**
The cluster consists of **three identical servers (nodes) by default**, but its architecture is designed to be **scalable to 5, 7, or more nodes**. Each node hosts:
1.  A complete and ready-to-start Mailcow Dockerized installation.
2.  A MariaDB database server, configured to use the shared, persistent storage.
3.  The cluster management service (`Mailcow-HA`).
4.  Keepalived.

At any given time, only one of these nodes is designated as **`MASTER`** and actively handles traffic. The others are in a hot-standby **`BACKUP`** state, ready to take over.

##### üß† **Pillar 2: The Brain - The Mailcow-HA Orchestrator**
Our suite of orchestration scripts is the true conductor of the cluster. It uses **Keepalived** as an engine to manage a complex high-availability logic:
*   **Floating IP Management:** The orchestrator is solely responsible for assigning the cluster's unique public IP. This is the single entry point for all users.
*   **Application Monitoring:** An intelligent monitoring script runs at regular intervals to deeply probe the state of the Mailcow stack (running containers, health status, etc.).
*   **Action Orchestration:** Based on the monitor's verdict, the orchestrator makes decisions. If it promotes a node to `MASTER`, it runs a promotion script. If it demotes it to `BACKUP`, it runs a demotion script. In all cases, you are **alerted in real-time** when a failover begins and when it successfully completes.

##### üíæ **Pillar 3: The Centralized and Resilient Database**
The database is no longer a potential point of failure. It uses a dedicated, high-performance block storage volume that operates on the same principle as the main file storage.
*   **Single Master Access:** The MariaDB data volume is a "floating" resource, attached exclusively to the active `MASTER` node. This architecture completely prevents any risk of data corruption (split-brain) since only one server can write to the database at any given time.
*   **High Performance & Security:** All database operations occur over a secure, high-speed private network connecting the server to its storage, ensuring minimal latency and complete isolation of critical data traffic.
*   **Instant Failover:** During a failover, the volume is detached from the old `MASTER` and re-attached to the new one in seconds, ensuring data persistence and consistency without complex synchronization.

##### üóÉÔ∏è **Pillar 4: Centralized File Storage**
To ensure perfect consistency and simplify management, a **single shared block storage volume** is used to centralize all of Mailcow's "stateful" data (emails, indexes, certificates, etc.).
*   **Mechanism:** This is a "floating" resource, dynamically attached to the active `MASTER` node. It is never accessible by more than one node at a time.
*   **Benefit:** This centralization provides **enhanced ease of backup and restore**. A full backup can be performed from any node, as the data is always an exact reflection of the service's state.

---

### 3. Anatomy of an Automatic Failover (A to Z)

Here is the precise, step-by-step sequence of events when a failure occurs on the `MASTER` node.

1.  **The Failure:** A critical container (e.g., `dovecot-mailcow`) on the `MASTER` crashes.

2.  **The Detection:**
    *   **Instantly**, the monitoring script detects that the service is no longer in 100% `Operational` state.
    *   It returns an error code to the orchestrator.

3.  **The Decision:**
    *   The orchestrator on the `MASTER` receives the error code. It immediately enters the `FAULT` state and relinquishes its `MASTER` role, notifying the other cluster members.

4.  **The Election:**
    *   The `BACKUP` nodes see that the `MASTER` has disappeared. The node with the highest priority elects itself as the new `MASTER`.

5.  **The Orchestration (on the new `MASTER`)**:
    *   Upon its promotion, the orchestrator runs the promotion script.
    *   This script executes its critical sequence:
        *   a. **Circuit Breaker Check:** It checks if a failover has already occurred on this node less than a user-defined time ago (**1 hour by default**). If so, it stops and sends an alert to prevent a failover loop.
         *   b. **Timestamp Update:** It records the start of the failover to grant a grace period to the monitoring system.
         *   c. **Resource Failover (in parallel):** It launches simultaneous API calls to reassign the **shared volume** and the **Floating IP**.
         *   d. **Wait and Mount:** It waits for confirmation that both operations are complete, then **mounts** the shared volume.
         *   e. **Service Start-up:** It starts the Mailcow Docker containers and ensures they are all fully operational.

6.  **The Grace Period:**
    *   While the promotion script is working (**in just a few seconds**, depending on machine performance), the monitoring script on the new `MASTER` is patient, as it has detected that a failover has just begun.

7.  **The Cleanup (on the old `MASTER`)**:
    *   Meanwhile, the orchestrator on the old `MASTER` (now in `BACKUP` state) runs a demotion script that cleanly stops any remaining containers and **unmounts** the volume.

8.  **Return to Normal:**
    *   On the new `MASTER`, the containers stabilize. The service is once again 100% operational. A success alert is sent to the administrator.

Rest assured, from the moment a failure is detected to the moment the service is available again, **only a few seconds elapse!**

Meanwhile, a **dual monitoring system** (an internal smart monitor and an external one via [Uptime Kuma](https://github.com/louislam/uptime-kuma)) ensures total visibility and instantly alerts the administrator without flooding them with notifications. Additionally, "garbage collector" scripts run at regular intervals to clean up any potential residues.

<br>
<p align="center">
  <strong><a href="./help.md">‚û°Ô∏è Learn more about our Professional services in help.md</a></strong>
</p>
<br>

</details>

<br>

<details>
<summary><strong>üá´üá∑ Version Fran√ßaise (cliquer pour d√©plier)</strong></summary>

### üìÑ Architecture Technique D√©taill√©e

### 1. Philosophie et Objectifs

Une instance Mailcow standard, bien que performante, constitue un **point de d√©faillance unique (SPOF)**. Une panne mat√©rielle, une erreur de mise √† jour ou un dysfonctionnement d'un conteneur critique suffit √† rendre l'ensemble du service de messagerie indisponible.

L'objectif de **Mailcow-HA** est de transformer cette instance unique en un **cluster r√©silient de type Actif/Passif**, capable de survivre √† la plupart des pannes en basculant automatiquement le service sur un n≈ìud de secours, avec une intervention humaine nulle et une interruption de service minimale.

La solution est con√ßue comme une **surcouche d'orchestration** qui s'int√®gre √† une installation Mailcow standard sans en modifier le c≈ìur, garantissant ainsi la compatibilit√© avec les futures mises √† jour de Mailcow.

---

### 2. Les Quatre Piliers de l'Infrastructure

La robustesse du cluster repose sur quatre composants fondamentaux qui travaillent de concert.

##### üèõÔ∏è **Pilier 1 : Les N≈ìuds Applicatifs**
Le cluster est compos√© de **trois serveurs (n≈ìuds) identiques par d√©faut**, mais son architecture est con√ßue pour √™tre **extensible √† 5, 7 n≈ìuds ou plus**. Chaque n≈ìud h√©berge :
1.  Une installation compl√®te de Mailcow Dockerized, pr√™te √† d√©marrer.
2.  Un serveur de base de donn√©es MariaDB, configur√© pour utiliser le stockage partag√© et persistant.
3.  Le service de gestion du cluster (`Mailcow-HA`).
4.  Keepalived.

√Ä tout instant, un seul de ces n≈ìuds est d√©sign√© **`MASTER`** et traite activement le trafic. Les autres sont en √©tat de **`BACKUP`** (hot-standby), pr√™ts √† prendre le relais.

##### üß† **Pilier 2 : Le Cerveau - L'Orchestrateur Mailcow-HA**
Notre suite de scripts d'orchestration est le v√©ritable chef d'orchestre du cluster. Elle utilise **Keepalived** comme moteur pour g√©rer une logique de haute disponibilit√© complexe :
*   **Gestion de l'IP Flottante :** L'orchestrateur est le seul responsable de l'assignation de l'IP publique unique du cluster. C'est le point d'entr√©e de tous les utilisateurs.
*   **Surveillance Applicative :** Un script de surveillance intelligent est ex√©cut√© √† intervalle r√©gulier pour sonder en profondeur l'√©tat de la pile Mailcow (conteneurs actifs, √©tat de sant√©, etc.).
*   **Orchestration des Actions :** En fonction du verdict du moniteur, l'orchestrateur prend des d√©cisions. S'il promeut un n≈ìud en `MASTER`, il ex√©cute un script de promotion. S'il le r√©trograde en `BACKUP`, il ex√©cute un script de r√©trogradation. Dans tous les cas, vous √™tes **alert√© en temps r√©el** du d√©but et de la fin de la bascule.

##### üíæ **Pilier 3 : La Base de Donn√©es Centralis√©e et R√©siliente**
La base de donn√©es n'est plus un point de d√©faillance. Elle utilise un volume de stockage bloc d√©di√© et performant qui fonctionne sur le m√™me principe que le stockage de fichiers principal.
*   **Acc√®s Master Unique :** Le volume de donn√©es de MariaDB est une ressource "flottante", attach√©e exclusivement au n≈ìud `MASTER` actif. Cette architecture pr√©vient tout risque de corruption de donn√©es (split-brain), car un seul serveur peut √©crire dans la base de donn√©es √† un instant T.
*   **Haute Performance et S√©curit√© :** Toutes les op√©rations de la base de donn√©es s'effectuent via un r√©seau priv√© s√©curis√© et √† haute vitesse connectant le serveur √† son stockage, garantissant une latence minimale et une isolation compl√®te du trafic de donn√©es critiques.
*   **Bascule Instantan√©e :** Lors d'une bascule, le volume est d√©tach√© de l'ancien `MASTER` et rattach√© au nouveau en quelques secondes, assurant la persistance et la coh√©rence des donn√©es sans n√©cessiter de synchronisation complexe.

##### üóÉÔ∏è **Pilier 4 : Le Stockage Centralis√© des Fichiers**
Pour garantir une coh√©rence parfaite et simplifier la gestion, un **unique volume de stockage bloc partag√©** est utilis√© pour centraliser toutes les donn√©es "stateful" de Mailcow (e-mails, index, certificats, etc.).
*   **M√©canisme :** Ce volume est une ressource "flottante", attach√©e dynamiquement au n≈ìud `MASTER` actif. Il n'est jamais accessible par plus d'un n≈ìud √† la fois.
*   **B√©n√©fice :** Cette centralisation garantit une **facilit√© accrue de sauvegarde et de restauration**. Une sauvegarde compl√®te peut √™tre effectu√©e depuis n'importe quel n≈ìud, car les donn√©es sont toujours le reflet exact de l'√©tat du service.

---

### 3. Anatomie d'une Bascule Automatique (de A √† Z)

Voici le d√©roulement pr√©cis, √©tape par √©tape, lorsqu'une panne survient sur le n≈ìud `MASTER`.

1.  **La Panne :** Un conteneur critique (ex: `dovecot-mailcow`) sur le `MASTER` plante.

2.  **La D√©tection :**
    *   **Instantan√©ment**, le script de surveillance d√©tecte que le service n'est plus √† 100% l'√©tat `Op√©rationnel`.
    *   Il retourne un code d'erreur √† l'orchestrateur.

3.  **La D√©cision :**
    *   L'orchestrateur sur le `MASTER` re√ßoit le code d'erreur. Il entre imm√©diatement dans l'√©tat `FAULT` et abandonne son r√¥le, notifiant les autres membres du cluster.

4.  **L'√âlection :**
    *   Les n≈ìuds `BACKUP` voient que le `MASTER` a disparu. Le n≈ìud avec la plus haute priorit√© s'√©lit lui-m√™me comme nouveau `MASTER`.

5.  **L'Orchestration (sur le nouveau `MASTER`)**:
    *   D√®s sa promotion, l'orchestrateur ex√©cute le script de promotion.
    *   Celui-ci ex√©cute sa s√©quence critique :
         *   a. **V√©rification du Disjoncteur :** Il v√©rifie si une bascule a d√©j√† eu lieu sur ce n≈ìud il y a moins d'un temps d√©fini par l'administrateur (**1 heure par d√©faut**). Si c'est le cas, il s'arr√™te et envoie une alerte pour √©viter une boucle de basculement.
         *   b. **Mise √† Jour des Chronom√®tres :** Il enregistre le d√©but de la bascule pour accorder une p√©riode de gr√¢ce √† la surveillance.
         *   c. **Bascule des Ressources (en parall√®le) :** Il lance les appels pour r√©assigner le **volume partag√©** et l'**IP Flottante** simultan√©ment.
         *   d. **Attente et Montage :** Il attend la confirmation que les deux op√©rations sont termin√©es, puis il **monte** le volume partag√©.
         *   e. **D√©marrage des Services :** Il d√©marre les services (conteneurs Docker) de Mailcow et s'assure qu'ils sont tous en √©tat de fonctionnement.

6.  **La P√©riode de Gr√¢ce :**
    *   Pendant que le script de promotion travaille (**en √† peine quelques secondes**, selon la performance des machines), le script de surveillance du nouveau `MASTER` est patient, car il a d√©tect√© le d√©but d'une bascule.

7.  **Le Nettoyage (sur l'ancien `MASTER`)**:
    *   Pendant ce temps, l'orchestrateur sur l'ancien `MASTER` (maintenant en `BACKUP`) ex√©cute un script de r√©trogradation qui arr√™te proprement les conteneurs restants et **d√©monte** le volume.

8.  **Le Retour √† la Normale :**
    *   Sur le nouveau `MASTER`, les conteneurs se stabilisent. Le service est de nouveau 100% op√©rationnel. Une alerte de succ√®s est envoy√©e √† l'administrateur.

Rassurez-vous, entre l'instant o√π la panne est d√©tect√©e et la disponibilit√© √† nouveau du service, il ne s'√©coule **qu'√† peine quelques secondes** !

Pendant ce temps, une **double surveillance** (une interne gr√¢ce √† un monitoring intelligent et une autre externe via [Uptime Kuma](https://github.com/louislam/uptime-kuma)) garantit une visibilit√© totale et alerte instantan√©ment l'administrateur sans l'inonder de notifications. De plus, des scripts "ramasse-miettes" s'ex√©cutent √† intervalle r√©gulier pour nettoyer les r√©sidus potentiels.

<br>
<p align="center">
  <strong><a href="./help.md">‚û°Ô∏è D√©couvrez nos services Professionnels dans help.md</a></strong>
</p>
<br>

</details>
<br>
<div align="center">

<table tyle="width: 100%; table-layout:fixed; border:1px solid #ddd; border-collapse:collapse;">
  <tr>
    <th width="50%" style="padding:10px;">üá¨üáß <b>Anglais</b></th>
    <th width="50%" style="padding:10px;">üá´üá∑ <b>Fran√ßais</b></th>
  </tr>
  <tr>
    <td>Youtube demonstration, mailcow ISP - High availability in action. <b>Failure detection and automatic failover</b></td>
    <td>D√©monstration Youtube, mailcow ISP - Haute disponibilit√© en action. <b>D√©tection de panne et basculement automatique</b></td>
  </tr>
  <tr>
    <td colspan="2" align="center" style="padding:15px; position:relative;"><br>
      <a href="https://www.youtube.com/watch?v=IloqWSzUiaI" target="_new">
        <img src="maicow-isp-ha.png" alt="mailcow ISP - High availability in action" height="100%" width="90%">
      </a>
    <br><br>
    </td>
  </tr>
</table>

<br><br>

<table style="width: 100%; table-layout:fixed; border:1px solid #ddd; border-collapse:collapse;">
  <tr>
    <th width="50%">üá¨üáß <b>Anglais</b></th>
    <th width="50%">üá´üá∑ <b>Fran√ßais</b></th>
  </tr>
  <tr>
    <td>Youtube Demo, Mailcow ISP - <b>Automatic Registration</b></td>
    <td>D√©monstration Youtube, mailcow ISP - <b>Inscription automatique</b></td>
  </tr>
  <tr>
    <td colspan="2" align="center">
        <br>
      <a href="https://www.youtube.com/watch?v=wEbo20yiaYA" target="_new">
         <img src="signup.png" alt="Mailcow ISP" style="height: 50%; width: 50%;">
      </a>
   <br><br>
    </td>
  </tr>
</table>

</div>
